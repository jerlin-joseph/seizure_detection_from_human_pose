{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = pd.read_excel('data/EEG Video Timings.xlsx')\n",
    "type_col_name = list(filter(lambda s: s.startswith('Type'), video_data.columns))[0]\n",
    "generalized_sz = video_data[video_data[type_col_name] == 0]\n",
    "fnames = 'data/videos/' + generalized_sz['Filename']+'.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_sz['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform keypoints to distances and angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Calculate Angles 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FRAME_WIDTH = 960\n",
    "FRAME_HEIGHT = 540\n",
    "def angle_between_3d(landmarks, a_img, b_img, c_img, prefix=''):\n",
    "    '''Given a row of landmarks with columns x0, y0, z0 ... x32, y32, z32; and 3\n",
    "    point numbers a, b, and c, this function finds the measure of angle ABC,\n",
    "    with point B at the vertex. Returns angle in radians'''\n",
    "\n",
    "    # the reference image is 1-indexed\n",
    "    a = a_img - 1\n",
    "    b = b_img - 1\n",
    "    c = c_img - 1\n",
    "\n",
    "    xa = landmarks[prefix+'x'+str(a)]\n",
    "    ya = landmarks[prefix+'y'+str(a)]\n",
    "    za = landmarks[prefix+'z'+str(a)] * FRAME_WIDTH\n",
    "\n",
    "    xb = landmarks[prefix+'x'+str(b)]\n",
    "    yb = landmarks[prefix+'y'+str(b)]\n",
    "    zb = landmarks[prefix+'z'+str(b)] * FRAME_WIDTH\n",
    "\n",
    "    xc = landmarks[prefix+'x'+str(c)]\n",
    "    yc = landmarks[prefix+'y'+str(c)]\n",
    "    zc = landmarks[prefix+'z'+str(c)] * FRAME_WIDTH\n",
    "\n",
    "    side_a = np.sqrt(np.power(xb - xc, 2) + np.power(yb - yc, 2) + np.power(zb - zc, 2))\n",
    "    side_b = np.sqrt(np.power(xa - xc, 2) + np.power(ya - yc, 2) + np.power(za - zc, 2))\n",
    "    side_c = np.sqrt(np.power(xb - xa, 2) + np.power(yb - ya, 2) + np.power(zb - za, 2))\n",
    "\n",
    "    numer = np.power(side_a, 2) + np.power(side_c, 2) - np.power(side_b, 2)\n",
    "    denom = 2 * side_a * side_c\n",
    "    try:\n",
    "        return np.arccos(numer/denom)\n",
    "        # return np.abs(np.arctan((yc - yb) / (xc - xb)) - np.arctan((ya - yb) / (xa - xb)))\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def distance_between_3d(landmarks, a_img, b_img, prefix=''):\n",
    "    a = a_img - 1\n",
    "    b = b_img - 1\n",
    "\n",
    "    xa = landmarks[prefix+'x'+str(a)]\n",
    "    ya = landmarks[prefix+'y'+str(a)]\n",
    "    za = landmarks[prefix+'z'+str(a)] * FRAME_WIDTH\n",
    "\n",
    "    xb = landmarks[prefix+'x'+str(b)]\n",
    "    yb = landmarks[prefix+'y'+str(b)]\n",
    "    zb = landmarks[prefix+'z'+str(b)] * FRAME_WIDTH\n",
    "\n",
    "    return np.sqrt((xa - xb) **2 + (ya - yb) **2 + (za - zb) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Calculate Angles 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def angle_between(landmarks, a_img, b_img, c_img, prefix=''):\n",
    "    '''Given a row of landmarks with columns x0, y0, z0 ... x32, y32, z32; and 3\n",
    "    point numbers a, b, and c, this function finds the measure of angle ABC,\n",
    "    with point B at the vertex. Returns angle in radians'''\n",
    "\n",
    "    # the reference image is 1-indexed\n",
    "    a = a_img - 1\n",
    "    b = b_img - 1\n",
    "    c = c_img - 1\n",
    "\n",
    "    xa = landmarks[prefix+'x'+str(a)]\n",
    "    ya = landmarks[prefix+'y'+str(a)]\n",
    "    # za = landmarks[prefix+'z'+str(a)] * FRAME_WIDTH\n",
    "\n",
    "    xb = landmarks[prefix+'x'+str(b)]\n",
    "    yb = landmarks[prefix+'y'+str(b)]\n",
    "    # zb = landmarks[prefix+'z'+str(b)] * FRAME_WIDTH\n",
    "\n",
    "    xc = landmarks[prefix+'x'+str(c)]\n",
    "    yc = landmarks[prefix+'y'+str(c)]\n",
    "    # zc = landmarks[prefix+'z'+str(c)] * FRAME_WIDTH\n",
    "\n",
    "    side_a = np.sqrt(np.power(xb - xc, 2) + np.power(yb - yc, 2))\n",
    "    side_b = np.sqrt(np.power(xa - xc, 2) + np.power(ya - yc, 2))\n",
    "    side_c = np.sqrt(np.power(xb - xa, 2) + np.power(yb - ya, 2))\n",
    "\n",
    "    numer = np.power(side_a, 2) + np.power(side_c, 2) - np.power(side_b, 2)\n",
    "    denom = 2 * side_a * side_c\n",
    "    try:\n",
    "        return np.arccos(numer/denom)\n",
    "        # return np.abs(np.arctan((yc - yb) / (xc - xb)) - np.arctan((ya - yb) / (xa - xb)))\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def distance_between(landmarks, a_img, b_img, prefix=''):\n",
    "    a = a_img - 1\n",
    "    b = b_img - 1\n",
    "\n",
    "    xa = landmarks[prefix+'x'+str(a)]\n",
    "    ya = landmarks[prefix+'y'+str(a)]\n",
    "    # za = landmarks[prefix+'z'+str(a)] * FRAME_WIDTH\n",
    "\n",
    "    xb = landmarks[prefix+'x'+str(b)]\n",
    "    yb = landmarks[prefix+'y'+str(b)]\n",
    "    # zb = landmarks[prefix+'z'+str(b)] * FRAME_WIDTH\n",
    "\n",
    "    return np.sqrt((xa - xb) **2 + (ya - yb) **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = ['R_axilla', 'L_axilla', 'R_elbow', 'L_elbow', 'R_ulnar_wrist', \n",
    "          'L_ulnar_wrist', 'R_thumb', 'L_thumb', 'R_hip', 'L_hip', 'R_knee',\n",
    "          'L_knee', 'R_neck', 'L_neck', 'R_arm', 'L_arm', 'R_forearm',\n",
    "          'L_forearm', 'R_thigh', 'L_thigh', 'R_leg', 'L_leg', \n",
    "          \n",
    "          'R_mouth_angle',\n",
    "          'Upper_mouth_0', 'Upper_mouth_1', \n",
    "          'Upper_mouth_2', 'Upper_mouth_3', 'Upper_mouth_4', \n",
    "          'L_mouth_angle', \n",
    "          'Lower_mouth_0', 'Lower_mouth_1', \n",
    "          'Lower_mouth_2', 'Lower_mouth_3', 'Lower_mouth_4',\n",
    "          \n",
    "          'R_lateral_canthus', \n",
    "          'R_medial_canthus',\n",
    "          'L_lateral_canthus', \n",
    "          'L_medial_canthus',\n",
    "\n",
    "          'R_eye_height',\n",
    "          'L_eye_height',\n",
    "          'Mouth_height',\n",
    "\n",
    "          # *['v'+str(i) for i in range(33)]\n",
    "          ]\n",
    "# add column labels for confidences at the end\n",
    "conf_labels = ['conf'+str(i) for i in range(133)]\n",
    "for col in conf_labels:\n",
    "    angles.append(col)\n",
    "\n",
    "def all_the_angles(df) -> pd.DataFrame:\n",
    "    '''\n",
    "    Given a df of pose landmarks, returns an array of important angles to\n",
    "    remove location-dependency of data\n",
    "\n",
    "    see MediaPipe docs for the pose mapping: \n",
    "    https://google.github.io/mediapipe/solutions/pose.html'''\n",
    "\n",
    "    column_data = [\n",
    "        ### POSE\n",
    "        angle_between_3d(df, 9, 7, 13), # R axilla\n",
    "        angle_between_3d(df, 8, 6, 12), # L axilla\n",
    "        angle_between_3d(df, 7, 9, 11), # R elbow\n",
    "        angle_between_3d(df, 6, 8, 10), # L elbow\n",
    "        angle_between(df, 9, 11, 130), # R ulnar wrist\n",
    "        angle_between(df, 8, 10, 109), # L ulnar wrist\n",
    "        angle_between(df, 9, 11, 118), # R thumb\n",
    "        angle_between(df, 8, 10, 97), # L thumb\n",
    "        angle_between_3d(df, 7, 13, 15), # R hip\n",
    "        angle_between_3d(df, 6, 12, 14), # L hip\n",
    "        angle_between_3d(df, 13, 15, 17), # R knee\n",
    "        angle_between_3d(df, 12, 14, 16), # L knee\n",
    "        angle_between_3d(df, 1, 5, 7),   # R \"neck\"\n",
    "        angle_between_3d(df, 1, 4, 6),   # L \"neck\"\n",
    "\n",
    "        distance_between_3d(df, 7, 9),  # R arm\n",
    "        distance_between_3d(df, 6, 8),  # L arm\n",
    "        distance_between_3d(df, 9, 11),  # R forearm\n",
    "        distance_between_3d(df, 8, 10),  # L forearm\n",
    "        distance_between_3d(df, 13, 15),  # R thigh\n",
    "        distance_between_3d(df, 12, 14),  # L thigh\n",
    "        distance_between_3d(df, 15, 17),  # R leg\n",
    "        distance_between_3d(df, 14, 16),  # L leg\n",
    "        ### FACE\n",
    "        angle_between(df, 83, 72, 73), # R mouth angle\n",
    "        angle_between(df, 72, 73, 74),\n",
    "        angle_between(df, 73, 74, 75),\n",
    "        angle_between(df, 74, 75, 76),\n",
    "        angle_between(df, 75, 76, 77),\n",
    "        angle_between(df, 76, 77, 78),\n",
    "        angle_between(df, 77, 78, 79), # L mouth angle\n",
    "        angle_between(df, 78, 79, 80),\n",
    "        angle_between(df, 79, 80, 81),\n",
    "        angle_between(df, 80, 81, 82),\n",
    "        angle_between(df, 81, 82, 83),\n",
    "        angle_between(df, 82, 83, 72),\n",
    "\n",
    "        ### EYES\n",
    "        angle_between(df, 65, 60, 61),  # R lateral canthus\n",
    "        angle_between(df, 62, 63, 64),  # R medial canthus\n",
    "        angle_between(df, 70, 69, 68),  # L lateral canthus\n",
    "        angle_between(df, 67, 66, 71),  # L medial canthus\n",
    "\n",
    "        distance_between(df, 62, 64), # R eye height\n",
    "        distance_between(df, 67, 71), # L eye height\n",
    "        distance_between(df, 86, 90), # mouth height\n",
    "    ]\n",
    "    confs = df[conf_labels]\n",
    "    column_data = np.append(np.array(column_data).transpose(), confs, axis=1) \n",
    "\n",
    "    new_df = pd.DataFrame(data=column_data)\n",
    "    new_df.columns = angles\n",
    "    return new_df\n",
    "\n",
    "def compute_angles(df: pd.DataFrame):\n",
    "    df_angles = all_the_angles(df)\n",
    "    df_angles['class'] = df['class']\n",
    "    if 'pt_id' in df.columns:\n",
    "        df_angles['pt_id'] = df['pt_id']\n",
    "    if 'vid_id' in df.columns:\n",
    "        df_angles['vid_id'] = df['vid_id']\n",
    "    # SKLearn's HistGradientBoostingClassifier cna handle NA values,\n",
    "    # so I'd like to see how that works\n",
    "    #return df_angles.drop('vid_id', axis=1)\n",
    "    #return df_angles.groupby(df_angles['vid_id']).fillna(method='ffill')\n",
    "    return df_angles.groupby(df_angles['vid_id']).ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Color Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"color_lookup = {\\n    6348578: 'tab:blue',\\n    2767430: 'tab:orange',\\n    5352576: 'tab:green',\\n    5514820: 'tab:red',\\n    5271491: 'tab:purple',\\n    5323733: 'tab:brown',\\n    6394294: 'tab:pink',\\n    5439586: 'tab:gray',\\n    2604950: 'tab:olive',\\n    5497695: 'tab:cyan',\\n    5447543: 'turquoise',\\n    5235825: 'gold',\\n    2940398: 'lightgreen',\\n    5512494: 'deeppink',\\n    #6381028: 'black',  #7953A100,7953A200,7953A300,7953A400,7953A501,7953A600,7953A700\\n    # new pts\\n    6338772: 'gray',\\n    6338772: 'gray',\\n    582992: 'gray', \\n    5489744: 'gray', \\n    5489744: 'gray'\\n}\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''color_lookup = {\n",
    "    6348578: 'tab:blue',\n",
    "    2767430: 'tab:orange',\n",
    "    5352576: 'tab:green',\n",
    "    5514820: 'tab:red',\n",
    "    5271491: 'tab:purple',\n",
    "    5323733: 'tab:brown',\n",
    "    6394294: 'tab:pink',\n",
    "    5439586: 'tab:gray',\n",
    "    2604950: 'tab:olive',\n",
    "    5497695: 'tab:cyan',\n",
    "    5447543: 'turquoise',\n",
    "    5235825: 'gold',\n",
    "    2940398: 'lightgreen',\n",
    "    5512494: 'deeppink',\n",
    "    #6381028: 'black',  #7953A100,7953A200,7953A300,7953A400,7953A501,7953A600,7953A700\n",
    "    # new pts\n",
    "    6338772: 'gray',\n",
    "    6338772: 'gray',\n",
    "    582992: 'gray', \n",
    "    5489744: 'gray', \n",
    "    5489744: 'gray'\n",
    "}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if I just change the color_lookup dictionary, I can get a test dataset to work on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Velocity and Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: data/pose/79611O00_dbx.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.signal import welch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "all_vid_df_times = []\n",
    "for _idx, row in generalized_sz.iterrows():\n",
    "    try:\n",
    "        df = pd.read_csv('data/pose/' + row['Filename']+'_dbx.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {'data/pose/' + row['Filename']+'_dbx.csv'}\")\n",
    "        continue\n",
    "\n",
    "    # only use the same patients that we've been using\n",
    "    '''if row['ID'] not in color_lookup.keys():\n",
    "        continue'''\n",
    "    \n",
    "    try:\n",
    "        m, s = row['Video\\nT0 to Start'].split(':')\n",
    "    # when the Start time is listed as \"-\", don't use this video\n",
    "    except ValueError:\n",
    "        continue\n",
    "    # 60 seconds per minute, 30 at the end is the fps\n",
    "    start_frame = (int(m) * 60 + int(s)) * 30\n",
    "    df['class'] = np.where(df.index < start_frame, 'nml', 'sz')\n",
    "    df['class'] = pd.Categorical(df['class'])\n",
    "    df['vid_id'] = row['Filename']\n",
    "    df_angles = compute_angles(df)\n",
    "\n",
    "    if 'vid_id' not in df_angles.columns:\n",
    "        df_angles['vid_id'] = df['vid_id']\n",
    "    df_angles['pt_id'] = row['ID']\n",
    "    df_angles = pd.concat([df_angles, df.loc[:,'xmin':'ymax']], axis=1)\n",
    "    v = df_angles.drop('pt_id', axis=1).drop('class', axis=1).groupby('vid_id').rolling(300).mean().diff(150)\n",
    "    # v = df_angles.drop('class', axis=1).groupby('vid_id').rolling(10).mean().diff(30)\n",
    "    v = v.rename(lambda x: 'v_'+x, axis=1)\n",
    "    a = v.reset_index().drop('level_1', axis=1).groupby('vid_id').diff()\n",
    "    a = a.rename(lambda x: 'a_'+x[2:], axis=1)\n",
    "\n",
    "    v = v.reset_index(drop=True)\n",
    "    a = a.reset_index(drop=True)\n",
    "    df_time = df_angles.merge(v, left_index=True, right_index=True).merge(a, left_index=True, right_index=True)\n",
    "    \n",
    "    all_vid_df_times.append(df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_vid_df_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.concat(all_vid_df_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time['pt_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time['vid_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_time.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that start with specific prefixes - velocity and acceleration calculations were done on conf\n",
    "# copy conf after velocity and acceleration calculations - TODO\n",
    "columns_to_drop = [col for col in df_time.columns if col.startswith((\"v_conf\", \"a_conf\", \"v_x\", \"v_y\", \"a_x\", \"a_y\"))]\n",
    "df_time = df_time.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file using pandas\n",
    "#df_time.to_pickle('data/df_time_30_60_without_detection.pkl')\n",
    "df_time.to_pickle('data/df_time_find_best.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cceb1fb107b2bbf4aedbf2536566f5eb68dedbd1bb981e112f990f33e36b1b78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
